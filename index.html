<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>FaceMesh Overlay â€“ MediaPipe + TF.js</title>

  <!-- MediaPipe FaceMesh -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest"></script>

  <style>
    html, body {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background: #000;
      height: 100%;
      width: 100%;
    }
    #video, #overlay {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: cover;
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>

  <script type="module">
    import { FaceLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest";

    const video = document.getElementById("video");
    const canvas = document.getElementById("overlay");
    const ctx = canvas.getContext("2d");

    let faceLandmarker, lastVideoTime = -1, results;

    async function init() {
      const filesetResolver = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
      );
      faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
        baseOptions: {
          modelAssetPath: "https://storage.googleapis.com/mediapipe-assets/face_landmarker.task"
        },
        runningMode: "VIDEO",
        outputFaceBlendshapes: false,
        numFaces: 1
      });

      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: "user" } });
      video.srcObject = stream;
      await video.play();

      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      requestAnimationFrame(detect);
    }

    function drawLandmarks(landmarks) {
      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      ctx.lineWidth = 0.5;
      ctx.strokeStyle = "rgba(0,255,0,0.7)";
      ctx.fillStyle = "rgba(0,255,0,0.8)";

      for (const lm of landmarks) {
        const x = lm.x * canvas.width;
        const y = lm.y * canvas.height;
        ctx.beginPath();
        ctx.arc(x, y, 1.2, 0, 2 * Math.PI);
        ctx.fill();
      }
    }

    async function detect() {
      if (!faceLandmarker) return;
      const now = video.currentTime;
      if (now === lastVideoTime) {
        requestAnimationFrame(detect);
        return;
      }
      lastVideoTime = now;

      results = faceLandmarker.detectForVideo(video, now);
      if (results && results.faceLandmarks.length > 0) {
        drawLandmarks(results.faceLandmarks[0]);
      }

      requestAnimationFrame(detect);
    }

    init();
  </script>
</body>
</html>
