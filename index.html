<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>BlazeFace Fast Grid Tracker</title>

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>

  <style>
    html, body {
      margin: 0; padding: 0;
      overflow: hidden;
      background: #000;
      height: 100%; width: 100%;
    }
    video, canvas {
      position: absolute;
      top: 0; left: 0;
      width: 100%; height: 100%;
      object-fit: cover;
    }
  </style>
</head>
<body>
  <video id="video" autoplay muted playsinline></video>
  <canvas id="overlay"></canvas>

  <script>
    let model, video, canvas, ctx;
    const GRID_ROWS = 15, GRID_COLS = 15;

    async function init() {
      await tf.setBackend('webgl');
      model = await blazeface.load({maxFaces: 1});
      console.log('BlazeFace loaded');

      // Setup webcam
      video = document.getElementById('video');
      const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
      video.srcObject = stream;
      await video.play();

      canvas = document.getElementById('overlay');
      ctx = canvas.getContext('2d');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      video.requestVideoFrameCallback(processFrame);
    }

    function drawGrid(box) {
      const [x1, y1] = box.topLeft;
      const [x2, y2] = box.bottomRight;
      const w = x2 - x1, h = y2 - y1;
      const dx = w / (GRID_COLS - 1), dy = h / (GRID_ROWS - 1);

      ctx.strokeStyle = "rgba(0,255,0,0.4)";
      ctx.lineWidth = 0.5;
      for (let r = 0; r < GRID_ROWS; r++) {
        ctx.beginPath();
        for (let c = 0; c < GRID_COLS; c++) {
          const px = x1 + c * dx;
          const py = y1 + r * dy;
          if (c === 0) ctx.moveTo(px, py);
          else ctx.lineTo(px, py);
        }
        ctx.stroke();
      }
      for (let c = 0; c < GRID_COLS; c++) {
        ctx.beginPath();
        for (let r = 0; r < GRID_ROWS; r++) {
          const px = x1 + c * dx;
          const py = y1 + r * dy;
          if (r === 0) ctx.moveTo(px, py);
          else ctx.lineTo(px, py);
        }
        ctx.stroke();
      }
    }

    async function processFrame(now, metadata) {
      await tf.nextFrame();
      const input = tf.tidy(() => {
        const tfImg = tf.browser.fromPixels(video);
        return tf.image.resizeBilinear(tfImg, [160, 160]).div(255).expandDims(0);
      });

      const predictions = await model.estimateFaces(video, false);

      ctx.clearRect(0, 0, canvas.width, canvas.height);
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      if (predictions.length > 0) {
        const face = predictions[0];
        drawGrid(face);
      }

      tf.dispose(input);
      video.requestVideoFrameCallback(processFrame);
    }

    init();
  </script>
</body>
</html>
